{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential Entropy and Control functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "from transformers import (\n",
    "    GPT2Tokenizer,\n",
    "    BertTokenizer,\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    AdamW,\n",
    "    GPT2Model,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    GPT2Config,\n",
    "    BertConfig,\n",
    "    BertModel\n",
    ")\n",
    "\n",
    "from src.utils.gpt2_letter_tokenizer import CustomGPT2Tokenizer, mGPTTokenizer, mBERTTokenizer\n",
    "from src.data.components.datasets import TokenTaggingDataset, tokenize_text_with_labels\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"it\"\n",
    "parameters = 4 \n",
    "mode = 'dct'\n",
    "\n",
    "LAB_ROOT = f\"/home/user/ding/Projects/Prosody/languages/{lang}/aligned\"\n",
    "PHONEME_LAB_ROOT = f\"/home/user/ding/Projects/Prosody/languages/{lang}/aligned\"\n",
    "WAV_ROOT = f\"/home/user/ding/Projects/Prosody/languages/{lang}/wav_files\"\n",
    "DATA_CACHE = f\"/home/user/ding/Projects/Prosody/languages/{lang}/cache\"\n",
    "\n",
    "TRAIN_FILE = \"train-clean-100\"\n",
    "VAL_FILE = \"dev-clean\"\n",
    "TEST_FILE = \"test-clean\"\n",
    "\n",
    "SAVE_DIR = f\"/home/user/ding/Projects/Prosody/precomputed/predictions/f0_{mode}_{parameters}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.f0_regression_datamodule import (\n",
    "    F0RegressionDataModule as DataModule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataModule(\n",
    "    wav_root=WAV_ROOT,\n",
    "    lab_root=LAB_ROOT,\n",
    "    phoneme_lab_root=PHONEME_LAB_ROOT,\n",
    "    data_cache=DATA_CACHE,\n",
    "    train_file=TRAIN_FILE,\n",
    "    val_file=VAL_FILE,\n",
    "    test_file=TEST_FILE,\n",
    "    dataset_name=f\"CommonVoice_{lang}\",\n",
    "    model_name=\"ai-forever/mGPT\",\n",
    "    f0_mode=mode,\n",
    "    f0_n_coeffs=parameters,\n",
    "    score_last_token=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ai-forever/mGPT tokenizer\n",
      "Dataloader: padding with token id: 5\n",
      "Loading data from cache: ('/home/user/ding/Projects/Prosody/languages/it/cache/train-clean-100', 'f0_dct_4.pkl')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing samples: 100%|██████████| 3991/3991 [00:02<00:00, 1565.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed 877/3991\n",
      "Loading data from cache: ('/home/user/ding/Projects/Prosody/languages/it/cache/dev-clean', 'f0_dct_4.pkl')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing samples: 100%|██████████| 499/499 [00:00<00:00, 2114.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed 107/499\n",
      "Loading data from cache: ('/home/user/ding/Projects/Prosody/languages/it/cache/test-clean', 'f0_dct_4.pkl')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing samples: 100%|██████████| 500/500 [00:00<00:00, 2228.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed 121/500\n",
      "Train dataset size: 3114\n",
      "Validation dataset size: 392\n",
      "Test dataset size: 379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of train, val, test in samples: (3991, 499, 500)\n"
     ]
    }
   ],
   "source": [
    "train_texts, train_labels = dm.train_texts, dm.train_durations\n",
    "val_texts, val_labels = dm.val_texts, dm.val_durations\n",
    "test_texts, test_labels = dm.test_texts, dm.test_durations\n",
    "\n",
    "print(\n",
    "    f\"Lengths of train, val, test in samples: {len(train_texts), len(val_texts), len(test_texts)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # double check\n",
    "# with open(f\"{DATA_CACHE}/{TRAIN_FILE}/f0_dct_4.pkl\", 'rb') as f1:\n",
    "#     train = pickle.load(f1)\n",
    "# train_texts = train[\"texts\"]\n",
    "# train_label = train[\"f0\"]\n",
    "\n",
    "# with open(f\"{DATA_CACHE}/{VAL_FILE}/f0_dct_4.pkl\", 'rb') as f2:\n",
    "#     val = pickle.load(f2)\n",
    "# val_texts = val[\"texts\"]\n",
    "# val_label = val[\"f0\"]\n",
    "\n",
    "# with open(f\"{DATA_CACHE}/{TEST_FILE}/f0_dct_4.pkl\", 'rb') as f3:\n",
    "#     test = pickle.load(f3)\n",
    "# test_texts = test[\"texts\"]\n",
    "# test_label = test[\"f0\"]\n",
    "\n",
    "# print(\n",
    "#     f\"Lengths of train, val, test in samples: {len(train_texts), len(val_texts), len(test_texts)}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def assign_labels(input_string, labels):\n",
    "    # Create list to hold words and punctuation\n",
    "    words_with_punctuation = re.findall(r'[\\u0E00-\\u0E7F\\w]+|[.,!?;\"-]|\\'', input_string) #words_with_punctuation = re.findall(r\"[\\w']+|[.,!?;\\\"-]|'\", input_string)\n",
    "\n",
    "    # Create list to hold only words\n",
    "    #words_only = re.findall(r\"\\w+'?\\w*\", input_string) #original\n",
    "    words_only= re.findall(r'[\\u0E00-\\u0E7F\\w]+', input_string) #gio\n",
    "\n",
    "\n",
    "    # Make sure the number of labels matches the number of words\n",
    "    if not len(labels) == len(words_only):\n",
    "        # alignmend or extraction failed, skip sample\n",
    "        return None, None, None\n",
    "\n",
    "    # Create a generator for word-label pairs\n",
    "    word_label_pairs = ((word, label) for word, label in zip(words_only, labels))\n",
    "\n",
    "    # Create list of tuples where each word is matched to a label and each punctuation is matched to None\n",
    "    words_with_labels = []\n",
    "    for token in words_with_punctuation:\n",
    "        #print(token)\n",
    "        if re.match(r'[\\u0E00-\\u0E7F\\w]+', token): # original: if re.match(r\"\\w+'?\\w*\", token):\n",
    "            #print(\"match\")\n",
    "            words_with_labels.append(next(word_label_pairs))\n",
    "        else:\n",
    "            words_with_labels.append((token, None))\n",
    "            #print(\"no match\")\n",
    "\n",
    "    return words_only, words_with_punctuation, words_with_labels\n",
    "\n",
    "\n",
    "def assign_labels_to_sentences(sentences, labels):\n",
    "    single_words = []\n",
    "    single_labels = []\n",
    "    for i in range(len(sentences)):\n",
    "        words_only, words_with_punct, words_with_labels = assign_labels(\n",
    "            sentences[i], labels[i]\n",
    "        )\n",
    "        # check if alignment failed\n",
    "        if words_only is None:\n",
    "            #print(f\"Alignment failed for sentence {i}\")\n",
    "            continue\n",
    "        #print(words_with_labels)\n",
    "        # remove Nones\n",
    "        words_with_labels = [(w, l) for w, l in words_with_labels if l is not None]\n",
    "        if len(words_with_labels) == 0:\n",
    "            #print(\"No labels for sentence {i}\")\n",
    "            continue\n",
    "        # process words and labels\n",
    "        words, word_labels = zip(\n",
    "            *[(w, l) for w, l in words_with_labels if l is not None]\n",
    "        )\n",
    "        single_words.extend(words)\n",
    "        single_labels.extend(word_labels)\n",
    "        \n",
    "\n",
    "    return single_words, single_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words and labels train: (31592, 31592)\n",
      "Words and labels dev: (3983, 3983)\n",
      "Words and labels test: (3838, 3838)\n",
      "Mean word length: 5.285388069926166\n"
     ]
    }
   ],
   "source": [
    "#from src.utils.text_processing import assign_labels_to_sentences\n",
    "\n",
    "all_train_words, all_train_labels = assign_labels_to_sentences(\n",
    "    train_texts, train_labels\n",
    ")\n",
    "all_dev_words, all_dev_labels = assign_labels_to_sentences(val_texts, val_labels)\n",
    "all_test_words, all_test_labels = assign_labels_to_sentences(test_texts, test_labels)\n",
    "\n",
    "print(f\"Words and labels train: {len(all_train_words), len(all_train_labels)}\")\n",
    "print(f\"Words and labels dev: {len(all_dev_words), len(all_dev_labels)}\")\n",
    "print(f\"Words and labels test: {len(all_test_words), len(all_test_labels)}\")\n",
    "\n",
    "all_words = all_train_words + all_dev_words + all_test_words\n",
    "\n",
    "# Compute the length of each word\n",
    "word_lengths = [len(word) for word in all_words]\n",
    "\n",
    "# Compute the mean word length\n",
    "mean_word_length = sum(word_lengths) / len(word_lengths)\n",
    "\n",
    "print(f\"Mean word length: {mean_word_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31592, 4), (3983, 4), (3838, 4))"
      ]
     },
     "execution_count": 895,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_labels = np.array(all_train_labels)\n",
    "all_dev_labels = np.array(all_dev_labels)\n",
    "all_test_labels = np.array(all_test_labels)\n",
    "\n",
    "all_train_labels.shape, all_dev_labels.shape, all_test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Combine all labels into a single dataset\n",
    "all_labels_combined = np.concatenate([all_train_labels, all_dev_labels, all_test_labels])\n",
    "\n",
    "# Step 1: Split into 80% train and 20% temporary (val+test)\n",
    "train_labels, temp_labels = train_test_split(all_labels_combined, test_size=0.2, random_state=234)\n",
    "\n",
    "# Step 2: Split 20% into 10% validation and 10% test\n",
    "dev_labels, test_labels = train_test_split(temp_labels, test_size=0.5, random_state=234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'index = 4\\nall_train_labels = all_train_labels[:,index]\\nall_dev_labels = all_dev_labels[:,index]\\nall_test_labels = all_test_labels[:,index]'"
      ]
     },
     "execution_count": 897,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''index = 4\n",
    "all_train_labels = all_train_labels[:,index]\n",
    "all_dev_labels = all_dev_labels[:,index]\n",
    "all_test_labels = all_test_labels[:,index]'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel density estimation and Differential Entropy Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_diff_entropy(density_func, samples, num_samples=10000):\n",
    "    if num_samples < samples.shape[1]:\n",
    "        samples = np.random.choice(samples, num_samples, replace=False)\n",
    "\n",
    "    log_densities = -np.log(density_func(samples))\n",
    "\n",
    "    entropy_estimate = np.mean(log_densities)\n",
    "\n",
    "    return entropy_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train_size: 3153, n_dev_size: 394, n_test_size: 394\n"
     ]
    }
   ],
   "source": [
    "# bootstrapping to get confidence intervals\n",
    "from sklearn.utils import resample\n",
    "from scipy.stats import gaussian_kde\n",
    "from src.utils.approximation import cross_validate_gkde_bandwidth\n",
    "\n",
    "n_train_size = int(len(train_labels) * 0.1)\n",
    "n_dev_size = int(len(dev_labels) * 0.1)\n",
    "n_test_size = int(len(test_labels) * 0.1)\n",
    "print(\n",
    "    f\"n_train_size: {n_train_size}, n_dev_size: {n_dev_size}, n_test_size: {n_test_size}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param scott, score -9.730869150608443\n",
      "new best param scott, score -9.730869150608443\n",
      "param silverman, score -9.730277088244076\n",
      "new best param silverman, score -9.730277088244076\n",
      "param 0.01, score -822.0661322779494\n",
      "param 0.1, score -14.7088512345511\n",
      "param 0.3, score -9.7586359595202\n",
      "best bw silverman\n"
     ]
    }
   ],
   "source": [
    "nb_train_samples = n_train_size #1500\n",
    "nb_dev_samples = n_dev_size #500\n",
    "nb_test_samples = n_test_size\n",
    "\n",
    "train_indices = np.random.choice(\n",
    "    np.arange(len(train_labels)), nb_train_samples, replace=False\n",
    ")\n",
    "train_data = train_labels[train_indices]\n",
    "dev_indices = np.random.choice(\n",
    "    np.arange(len(dev_labels)), nb_dev_samples, replace=False\n",
    ")\n",
    "dev_data = dev_labels[dev_indices]\n",
    "\n",
    "best_bw = cross_validate_gkde_bandwidth(\n",
    "    train_data=train_data.T,\n",
    "    test_data=dev_data.T,\n",
    ")\n",
    "print(f\"best bw {best_bw}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iteration 1 out of 10 with diff entropy: 9.809771739286505\n",
      "Finished iteration 2 out of 10 with diff entropy: 9.750048877661559\n",
      "Finished iteration 3 out of 10 with diff entropy: 9.504738913650513\n",
      "Finished iteration 4 out of 10 with diff entropy: 9.886439995081926\n",
      "Finished iteration 5 out of 10 with diff entropy: 9.693491221752105\n",
      "Finished iteration 6 out of 10 with diff entropy: 9.543142867248283\n",
      "Finished iteration 7 out of 10 with diff entropy: 9.546238112630961\n",
      "Finished iteration 8 out of 10 with diff entropy: 10.127104781056161\n",
      "Finished iteration 9 out of 10 with diff entropy: 9.628495771018496\n",
      "Finished iteration 10 out of 10 with diff entropy: 9.891696332708475\n",
      "Mean: 9.738116861209498, std: 0.18587108770835306\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "n_iterations = 10\n",
    "diff_entropy_list = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    train_sample = resample(train_labels, n_samples=n_train_size)\n",
    "    dev_sample = resample(dev_labels, n_samples=n_dev_size)\n",
    "    test_sample = resample(test_labels, n_samples=n_test_size)\n",
    "    # combined_sample = np.vstack([train_sample, dev_sample, test_sample])\n",
    "    # print(\"shape:\", test_sample.shape)\n",
    "    # best_bw = 0.01\n",
    "    # best_bw = cross_validate_gkde_bandwidth(train_sample.T, dev_sample.T)\n",
    "    # print(f\"Best bandwidth: {best_bw}\")\n",
    "    density = gaussian_kde(train_sample .T, bw_method=best_bw)\n",
    "    mc_entropy = monte_carlo_diff_entropy(density, test_sample.T, len(test_sample))\n",
    "    diff_entropy_list.append(mc_entropy)\n",
    "    print(\n",
    "        f\"Finished iteration {i+1} out of {n_iterations} with diff entropy: {mc_entropy}\"\n",
    "    )\n",
    "\n",
    "diff_entropy_list = np.array(diff_entropy_list)\n",
    "print(f\"Mean: {np.mean(diff_entropy_list)}, std: {np.std(diff_entropy_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prosody",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
